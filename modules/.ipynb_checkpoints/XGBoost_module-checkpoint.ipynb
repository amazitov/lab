{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import cross_validation,metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use get_train_test() to load data, keep defaults unless you want to use your own data\n",
      "Use xgboost_predict() to run model\n"
     ]
    }
   ],
   "source": [
    "# Загружаем данные из файлов 'angle','StructuralSums',etc\n",
    "# Примечание: все эти файлы должны лежать в одной директории с модулем, либо\n",
    "# нужно прописать путь к ним отдельно. \n",
    "def load_data(Balint = False, dataset=None): \n",
    "    angle = pd.read_csv('../FPs/angle', sep=',', header=None)\n",
    "    SS = pd.read_csv('../FPs/StructuralSums', header=None)\n",
    "    real = pd.read_csv('../FPs/real', header=None)\n",
    "    volume = pd.read_csv('../FPs/volume', header = None)\n",
    "    order = pd.read_csv('../FPs/order', header=None)\n",
    "    E = pd.read_csv('../FPs/Energy', header=None)\n",
    "    E_Balint = pd.read_csv('../FPs/Energy_Balint', header=None)\n",
    "    poscar = pd.read_csv('../FPs/Poscars', header = None)\n",
    "    \n",
    "    E_Balint = E_Balint.drop(0, axis=1) # Далее - чутка подготовки данных, чтобы проще было работать с датафреймом\n",
    "    \n",
    "    name_list = ['angle', 'SS', 'real', 'volume', 'order']\n",
    "    data_list = [angle, SS, real, volume, order]\n",
    "    \n",
    "    for i in range(len(data_list)):\n",
    "        index = []\n",
    "        for j in range(data_list[i].shape[1]):\n",
    "            index.append(name_list[i] + '%i'% j)\n",
    "        data_list[i].set_axis(1,[index])\n",
    "    \n",
    "    coefs = []\n",
    "    \n",
    "    for i in range(len(poscar)):\n",
    "        if poscar[0][i] == 'Au':\n",
    "            coefs.append(poscar[0][i+1])\n",
    "    coefs = pd.DataFrame(coefs)\n",
    "    for i in range(len(E)):\n",
    "        E[0][i] = E[0][i]/float(coefs[0][i]) # Делим энергии на количество атомов\n",
    "        E_Balint[1][i] = E_Balint[1][i]/float(coefs[0][i])\n",
    "    FP = pd.concat([angle, SS, real, volume, order], axis=1) # Подготавливаем первичную матрицу Х\n",
    "    \n",
    "    \n",
    "    index = [] #Чистим структуры с энергией больше нуля\n",
    "    for i in range(len(E[0])):\n",
    "        if E[0][i] > 0:\n",
    "            index.append(i)\n",
    "    E = E.drop(index)\n",
    "    E_Balint = E_Balint.drop(index)\n",
    "    FP = FP.drop(index)\n",
    "    \n",
    "    \n",
    "    if dataset == 'old_FP': # Указатели на тип загружаемого датасета и энергий\n",
    "        X = FP.astype(np.float32)\n",
    "        print 'Old FP used'\n",
    "    if dataset == 'new_FP':\n",
    "        X = pd.read_csv('FP', sep=',', header = None, dtype=np.float32)\n",
    "        X = X.drop(index)\n",
    "        print 'New FP used'\n",
    "    if not Balint: \n",
    "        y = E[0].astype(np.float32)\n",
    "        print \"DFT loaded\"\n",
    "    else:\n",
    "        y = E_Balint[1].astype(np.float32)\n",
    "        print \"Balint loaded\"\n",
    "    return X,y # Итоговые данные\n",
    "\n",
    "# Тут тоже немного чистим фичи, проверяем на отсутвие структур с энергией больше нуля\n",
    "def clean_data(X,y,yb): \n",
    "    for i in yb:\n",
    "        if i>0:\n",
    "            X.drop(yb[yb==i].index[0], inplace=True)\n",
    "            y.drop(yb[yb==i].index[0], inplace=True)\n",
    "            yb.drop(yb[yb==i].index[0], inplace=True)\n",
    "    X.index = range(0,len(X))\n",
    "    y.index = range(0,len(y))\n",
    "    yb.index = range(0,len(yb))\n",
    "    print \"All >0 deleted\"\n",
    "# Основная функция номер раз: подгружаем нашу загрузку данных и разбиваем на трейн и тест\n",
    "# Параметры None отвечают стандартной загрузке датасета. Если нужно обучиться на других данных, то\n",
    "# указываем их в аргументах\n",
    "def get_train_test(X=None,y=None,Xb=None,yb=None,test_size=0.25):\n",
    "    if (X == None) & (y==None):\n",
    "        X,y = load_data(dataset='old_FP', Balint=False)\n",
    "    print X.shape, y.shape\n",
    "    if (Xb == None) & (yb==None):\n",
    "        Xb, yb = load_data(dataset='old_FP', Balint=True)\n",
    "    print Xb.shape, yb.shape\n",
    "    clean_data(X,y,yb)\n",
    "    # Разбиение на трейн и тест\n",
    "    for itr, ite in cross_validation.ShuffleSplit(len(y), n_iter=5, train_size=(1.-test_size), test_size=test_size):\n",
    "        pass\n",
    "    \n",
    "    xtrain = X.loc[itr]\n",
    "    xtest = X.loc[ite]\n",
    "\n",
    "    ytrain = y.loc[itr]\n",
    "    ytest = y.loc[ite]\n",
    "\n",
    "    ybtrain = yb.loc[itr]\n",
    "    ybtest = yb.loc[ite]\n",
    "    \n",
    "    print 'Preparing delta(Y) as Y(DFT) - Y(Balint)'\n",
    "    dytrain = ytrain - ybtrain\n",
    "    dytest = ytest - ybtest\n",
    "    return xtrain, xtest, dytrain,dytest\n",
    "# Основная функция номер два. Идем по порядку.\n",
    "# Описание параметров: max_depth - максимальная глубина базовых деревьев, eta - коэффициент, с\n",
    "# которым новые деревья добавляются в композицию, numrounds - количество алгоритмов в композиции.\n",
    "# Остальные параметры можно не трогать, но если очень хочется - то гуглим, что они делают, здесь\n",
    "# кратко пробегусь. И еще, test_mode - флаг на отладку алгоритма при изменении параметров. Если хотим \n",
    "# оценить качество на кросс-валидации, то ставим True и смотрим. Нашли хорошие параметры - меняем\n",
    "# обратно на False и запускаем алгоритм для предсказания энергий.\n",
    "def xgboost_predict(xtrain,xtest,ytrain,ytest, max_depth=100,eta=0.01,numrounds=1000, test_mode = False):\n",
    "    # Это словарь параметров, используемых алгоритмом\n",
    "    param = {}\n",
    "    param['max_depth'] = max_depth \n",
    "    param['subsample'] = 0.75 # Размер случайной подвыборки, на которой алгоритм обучается (уменьшает переобученность)\n",
    "    param['rate_drop'] = 0.5 # Процент данных, которые пропускаются при обученнии (уменьшает переобученность)\n",
    "    param['booster'] = 'gbtree'# Базовый алгортим - дерево\n",
    "    param['objective'] = 'reg:linear' # Задача регрессии\n",
    "    param['eval_metric'] = 'rmse' # Метрика качества\n",
    "    param['eta'] = eta\n",
    "    \n",
    "    Xdatatrain = xgb.DMatrix(data = xtrain, label = ytrain) # Спец.вид матрицы, используемых алгоритмом\n",
    "    plst = list(param.items()) \n",
    "    if test_mode == True:\n",
    "        print param\n",
    "        res = xgb.cv(params=param, dtrain=Xdatatrain, num_boost_round=numrounds, nfold=5)\n",
    "    else:\n",
    "        print param\n",
    "        print 'Waiting for training...'\n",
    "        bst = xgb.train(plst, Xdatatrain, numrounds)\n",
    "        ypredxgb = bst.predict(xgb.DMatrix(xtest))\n",
    "        print 'RMSE error:', np.sqrt(metrics.mean_squared_error(ytest, ypredxgb))\n",
    "        return ypredxgb\n",
    "print 'Use get_train_test() to load data, keep defaults unless you want to use your own data\\nUse xgboost_predict() to run model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
